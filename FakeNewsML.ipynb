{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8106e8da",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7be3f3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import gradio as gr\n",
    "import warnings\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.inspection import permutation_importance\n",
    "from datasets import load_dataset\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ba5c34",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd82c824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "true_df = pd.read_csv(\"archive/True.csv\")\n",
    "false_df = pd.read_csv(\"archive/Fake.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b23735",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_df['auth'] = \"real\"\n",
    "false_df['auth'] = \"fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f55c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change classifications to binary\n",
    "true_df['label'] = 0\n",
    "false_df['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3447683",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine dfs\n",
    "news_df = pd.concat([true_df, false_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88460461",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# combine texts\n",
    "news_df['article'] = news_df['title'] + \":\" + news_df['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05369a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d79a14",
   "metadata": {},
   "source": [
    "# Testing models \n",
    "#### (Do not need to run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d563d5",
   "metadata": {},
   "source": [
    "## zero shot classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b59a02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use zero shot classifcation to train\n",
    "def zero_shot(df):\n",
    "    # Loads a pre-trained BART model for sequence classification\n",
    "    bart = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli')\n",
    "    \n",
    "    # Loads a tokenizer associated with the pre-trained model, which converts text into a format suitable for input into a machine learning model \n",
    "    tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')\n",
    "    \n",
    "    \n",
    "    results = {}\n",
    "    classifications = [\"true\", \"false\"]\n",
    "    \n",
    "    for classification in classifications:\n",
    "        statement = f\"This example is about {classification}.\"\n",
    "        \n",
    "        token = tokenizer.encode(df, statement, return_tensors = \"pt\", truncation = True)\n",
    "        \n",
    "        logits = bart(token)[0]\n",
    "        \n",
    "        contra_entail = logits[:, [0,2]]\n",
    "        \n",
    "        prob = contra_entail.softmax(dim=1)\n",
    "        true_label = prob[:, 1].item()\n",
    "        \n",
    "        results[classification] = true_label\n",
    "    return results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7b5ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes too long to run\n",
    "news_df['predict'] = news_df['article'].apply(lambda x: zero_shot(x[:512]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1185a31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the zero-shot classification pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "news_df['article'] = df['title'] + \":\" + df['text']\n",
    "\n",
    "news_df['bart_result'] = classifier(news_df['article'], news_df['subject'].unique())\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a5794c",
   "metadata": {},
   "source": [
    "# Final Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a963b622",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0135cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create training and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(news_df['article'], news_df['label'], test_size=0.2, random_state=42, stratify=df['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a3ea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using logistic regression to create binary classifications\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=10000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train_tfidf, y_train)\n",
    "y_pred = lr.predict(X_test_tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e08a15",
   "metadata": {},
   "source": [
    "## Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0613a1",
   "metadata": {},
   "source": [
    "#### Domain Specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26a0b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_domains = df.loc[X_test.index, 'subject']\n",
    "uv = df['subject'].unique()\n",
    "for domain in uv:\n",
    "    idx = test_domains == domain\n",
    "    print(f\"\\nDomain: {domain}\")\n",
    "    print(classification_report(y_test[idx], y_pred[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7d15cc",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dce077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance analysis\n",
    "features= np.array(tfidf.get_feature_names_out())\n",
    "importance = lr.coef_[0]\n",
    "pos = np.argsort(importance)[-15:]\n",
    "neg = np.argsort(importance)[:15]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(features[pos], importance[pos], color='blue')\n",
    "plt.barh(features[neg], importance[neg], color='orange')\n",
    "plt.title(\"Weight of Identified Key Words from Logistic Regression\")\n",
    "plt.xlabel(\"Weight\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262356cc",
   "metadata": {},
   "source": [
    "## Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ce47f0",
   "metadata": {},
   "source": [
    "### roBERTa Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa42044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in roberta model\n",
    "# tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "# model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-base\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"FacebookAI/roberta-base\", \n",
    "                                                         problem_type=\"multi_label_classification\",\n",
    "                                                         num_labels=2)\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def roberta(texts, batch_size=16):\n",
    "    preds = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(batch_texts.tolist(), return_tensors=\"pt\", truncation=True,\n",
    "                           padding=True, max_length=512).to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "        batch_preds = torch.argmax(logits, dim=1).cpu().tolist()\n",
    "        preds.extend(batch_preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd58e618",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "news_df['roberta'] = roberta(news_df['article'])\n",
    "\n",
    "print(classification_report(news_df['auth'], news_df['roberta'], target_names=[\"fake\", \"real\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
